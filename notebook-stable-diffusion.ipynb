{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbfbe89",
   "metadata": {},
   "source": [
    "# ç«¯åˆ°ç«¯ä½“éªŒAIGC-ä»SageMakeråˆ°Webåº”ç”¨\n",
    "\n",
    "ç”Ÿæˆå¼AIæŠ€æœ¯æ­£åœ¨è¿…é€Ÿæé«˜ï¼Œç°åœ¨å¯ä»¥ç®€å•åœ°æ ¹æ®æ–‡æœ¬è¾“å…¥æ¥ç”Ÿæˆæ–‡æœ¬å’Œå›¾åƒã€‚ æœ¬æ¬¡åŠ¨æ‰‹è®­ç»ƒè¥å°†é‡‡ç”¨Stable DiffusionğŸ§¨æ¨¡å‹ã€‚\n",
    "\n",
    "Stable DiffusionğŸ§¨æ˜¯ä¸€ç§æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œå¯è®©æ‚¨åˆ›å»ºé€¼çœŸçš„AIGCåº”ç”¨ç¨‹åºã€‚\n",
    "\n",
    "åœ¨æœ¬æ¬¡åŠ¨æ‰‹è®­ç»ƒè¥ä¸­ï¼Œæ‚¨å°†äº†è§£åˆ°:\n",
    " 1. Stable Diffusionæ¨¡å‹ç”Ÿæˆå›¾ç‰‡çš„è¿‡ç¨‹\n",
    " 2. åœ¨Sagemaker Notebook Instanceä¸­è¿è¡Œè¯¥æ¨¡å‹\n",
    " 3. ä½¿ç”¨Sagemaker Notebook Instanceéƒ¨ç½²æ¨¡å‹å¹¶è¿›è¡Œæ¨ç†\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d8464",
   "metadata": {},
   "source": [
    "## 1.å‡†å¤‡å·¥ä½œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55254b1a",
   "metadata": {},
   "source": [
    "### 1.1 å®‰è£…åŠç¯å¢ƒé…ç½®å·¥ä½œ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536af417",
   "metadata": {},
   "source": [
    "#### æ£€æŸ¥ç¯å¢ƒç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d83b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version\n",
    "!pip list | grep torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66083a9",
   "metadata": {},
   "source": [
    "#### å®‰è£…Notebookè¿è¡Œæ¨¡å‹æ‰€éœ€çš„åº“æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo yum-config-manager --disable docker-ce-stable\n",
    "!sudo yum -y install pigz\n",
    "!pip install -U pip\n",
    "!pip install -U transformers==4.29.2 diffusers==0.16.1 ftfy accelerate\n",
    "!pip install -U torch==1.13.1+cu117 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install -U sagemaker\n",
    "!pip list | grep torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa562670",
   "metadata": {},
   "source": [
    "### 1.2 ä¸‹è½½æ¨¡å‹æ–‡ä»¶\n",
    "\n",
    "#### ç›®å‰Stable Diffusionå‘å¸ƒäº†Stable Diffusion V1å’ŒStable Diffusion V2ç‰ˆæœ¬ã€‚\n",
    "\n",
    "èµ·åˆçš„[Stable Diffusion V1](https://github.com/CompVis/stable-diffusion) ç”± [CompVis](https://ommer-lab.com) é¢†å¯¼ï¼Œæ”¹å˜äº†å¼€æºäººå·¥æ™ºèƒ½æ¨¡å‹çš„æ€§è´¨ï¼Œå¹¶åœ¨å…¨çƒèŒƒå›´å†…å‚¬ç”Ÿäº†æ•°ç™¾ä¸ªå…¶ä»–æ¨¡å‹å’Œåˆ›æ–°ã€‚å®ƒæ˜¯æ‰€æœ‰è½¯ä»¶ä¸­æœ€å¿«è¾¾åˆ° 10K Github star çš„è½¯ä»¶ä¹‹ä¸€ï¼Œåœ¨ä¸åˆ°ä¸¤ä¸ªæœˆçš„æ—¶é—´å†…é£™å‡è‡³ 33K starã€‚\n",
    "\n",
    "Stable Diffusion V1ä½¿ç”¨*é™é‡‡æ ·å› å­8*(downsampling-factor 8)è‡ªåŠ¨ç¼–ç å™¨å’Œ860M UNetå’Œ CLIP ViT-L/14æ–‡æœ¬ç¼–ç å™¨ç”¨äºæ‰©æ•£æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨ 256x256 å›¾åƒä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶ååœ¨ 512x512 å›¾åƒä¸Šè¿›è¡Œå¾®è°ƒã€‚\n",
    "\n",
    "ä¸æœ€åˆçš„ V1 ç‰ˆæœ¬ç›¸æ¯”ï¼Œ[Stable Diffusion V2](https://github.com/Stability-AI/StableDiffusion) æä¾›äº†è®¸å¤šé‡å¤§æ”¹è¿›å’Œç‰¹æ€§ï¼Œå…·ä½“è¡¨ç°åœ¨ï¼š\n",
    "\n",
    "Stable Diffusion V2ç‰ˆæœ¬åŒ…å«ä¸€ä¸ªå…·æœ‰é²æ£’æ€§çš„æ–‡æœ¬ç”Ÿæˆå›¾åƒæ¨¡å‹ï¼Œåœ¨å…¨æ–°çš„æ–‡æœ¬ç¼–ç å™¨ (OpenCLIP) ä¸Šè®­ç»ƒè€Œæˆï¼Œä¸æ—©æœŸçš„ V1 ç‰ˆæœ¬ç›¸æ¯”ï¼Œæ–‡æœ¬ -> å›¾åƒæ¨¡å‹å¤§å¤§æé«˜äº†å›¾åƒç”Ÿæˆè´¨é‡ï¼Œå¯ä»¥ç”Ÿæˆé»˜è®¤åˆ†è¾¨ç‡ä¸º 512x512 åƒç´ å’Œ 768x768 åƒç´ çš„å›¾åƒã€‚\n",
    "\n",
    "- [Stable Diffusion Launch Announcement](https://stability.ai/blog/stable-diffusion-announcement)\n",
    "- [Stable Diffusion 2.0 Release](https://stability.ai/blog/stable-diffusion-v2-release)\n",
    "\n",
    "#### Stable Diffusionçš„å¼€æºæ¨¡å‹æ–‡ä»¶å­˜æ”¾åœ¨Hugging Faceä¸Šã€‚\n",
    "\n",
    "Hugging FaceğŸ¤— æ˜¯ä¸€ä¸ª AI/ML ç¤¾åŒºå’Œå¹³å°ï¼Œæ—©æœŸé  Transformers æ¨¡å‹åº“å’Œé«˜è´¨é‡ç¤¾åŒºå—åˆ°å…³æ³¨ã€‚ç”¨æˆ·å¯ä»¥åœ¨ Hugging Face ä¸Šæ‰˜ç®¡å’Œå…±äº« ML æ¨¡å‹ã€æ•°æ®é›†ï¼Œä¹Ÿå¯ä»¥æ„å»ºã€è®­ç»ƒå’Œéƒ¨ç½²æ¨¡å‹ã€‚æˆªè‡³ç›®å‰ï¼ŒHugging Face ä¸Šå…±æœ‰ 7.7 ä¸‡ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œä»¥ NLP æ¨¡å‹ä¸ºä¸»ï¼Œç›®å‰ NLP æ¨¡å‹å æ¯”ä¸º 50%ï¼Œ2022 å¹´åˆä¸º 70%ï¼Œè¿™ä¸€æ¯”ä¾‹æœªæ¥ä¼šç»§ç»­ä¸‹é™ã€‚Hugging Face ç°åœ¨æ˜¯ NLP é¢†åŸŸçš„ GitHubï¼Œæœªæ¥å¸Œæœ›æˆä¸ºæ•´ä¸ª ML é¢†åŸŸçš„ GitHubï¼Œå¹¶é€æ¸å‘ ML Workflow çš„å…¶ä»–ç¯èŠ‚æ¸—é€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda39128",
   "metadata": {},
   "source": [
    "### å®‰è£…git lfsä»¥å…‹éš†æ¨¡å‹ä»“åº“ ï¼ˆgit lfsæ”¯æŒå¤§æ–‡ä»¶ä¸Šä¼ ä¸ä¸‹è½½ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0351bea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!sudo sudo amazon-linux-extras install epel -y\n",
    "!sudo yum-config-manager --enable epel\n",
    "!sudo yum install git-lfs -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee77e9b2",
   "metadata": {},
   "source": [
    "### è®¾å®šæ¨¡å‹ç‰ˆæœ¬çš„ç¯å¢ƒå˜é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8853697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the Stable Diffusion model from HuggingFace\n",
    "\n",
    "#### Stable Diffusion V1\n",
    "SD_SPACE=\"runwayml/\"\n",
    "SD_MODEL = \"stable-diffusion-v1-5\"\n",
    "SD_EXCLUDE_MODEL=\"!v1-5-pruned.ckpt\"\n",
    "\n",
    "#### Stable Diffusion V2\n",
    "# SD_SPACE=\"stabilityai/\"\n",
    "# SD_MODEL = \"stable-diffusion-2-1\"\n",
    "# SD_EXCLUDE_MODEL=\"!v2-1_768-nonema-pruned.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3932cf",
   "metadata": {},
   "source": [
    "### å…‹éš†æ¨¡å‹ä»“åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db2b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated time to spend v1(3min),v2(4min)\n",
    "%cd ~/SageMaker\n",
    "!echo $(date)\n",
    "!printf \"=======Current Path========%s\\n\"\n",
    "!rm -rf $SD_MODEL\n",
    "!mkdir $SD_MODEL\n",
    "%cd $SD_MODEL\n",
    "!git init\n",
    "#Include / Exclude file\n",
    "!git config core.sparseCheckout true\n",
    "!echo \"/*\" >> .git/info/sparse-checkout\n",
    "!echo \"!**/*.safetensors\" >> .git/info/sparse-checkout\n",
    "!echo $SD_EXCLUDE_MODEL >> .git/info/sparse-checkout\n",
    "#Checkout and pull file\n",
    "!git remote add -f master https://huggingface.co/$SD_SPACE$SD_MODEL\n",
    "!git pull master main\n",
    "!rm -rf .git\n",
    "%cd ~/SageMaker\n",
    "!printf \"=======Folder========%s\\n$(ls)\\n\"\n",
    "!echo $(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe3b23",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.åœ¨Notebookä¸­é…ç½®å¹¶ä½¿ç”¨æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd041ff9",
   "metadata": {},
   "source": [
    "### åŠ è½½æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e4fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datetime\n",
    "from diffusers import StableDiffusionPipeline\n",
    "# Load stable diffusion\n",
    "pipe = StableDiffusionPipeline.from_pretrained(SD_MODEL, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef84a5dc",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨GPUè¿›è¡Œè¿ç®—å¹¶è®¾å®šå‚æ•°\n",
    "\n",
    "ä¸ºæ¨¡å‹è®¾å®šè¾“å…¥å‚æ•°ï¼Œå¯ä½¿ç”¨çš„éƒ¨åˆ†å‚æ•°å¦‚ä¸‹ï¼š\n",
    "- prompt (`str` or `List[str]`):\n",
    "  - å¼•å¯¼å›¾åƒç”Ÿæˆçš„æ–‡æœ¬æç¤ºæˆ–æ–‡æœ¬åˆ—è¡¨\n",
    "- height (`int`, *optional*, é»˜è®¤ä¸º V1æ¨¡å‹å¯æ”¯æŒåˆ°512åƒç´ ï¼ŒV2æ¨¡å‹å¯æ”¯æŒåˆ°768åƒç´ ):\n",
    "  - ç”Ÿæˆå›¾åƒçš„é«˜åº¦ï¼ˆä»¥åƒç´ ä¸ºå•ä½ï¼‰\n",
    "- width (`int`, *optional*,  é»˜è®¤ä¸º V1æ¨¡å‹å¯æ”¯æŒåˆ°512åƒç´ ï¼ŒV2æ¨¡å‹å¯æ”¯æŒåˆ°768åƒç´ ):\n",
    "  - ç”Ÿæˆå›¾åƒçš„å®½åº¦ï¼ˆä»¥åƒç´ ä¸ºå•ä½ï¼‰\n",
    "- num_inference_steps (`int`, *optional*, defaults to 50):\n",
    "  - é™å™ªæ­¥æ•°ã€‚æ›´å¤šçš„å»å™ªæ­¥éª¤é€šå¸¸ä¼šä»¥è¾ƒæ…¢çš„æ¨ç†ä¸ºä»£ä»·è·å¾—æ›´é«˜è´¨é‡çš„å›¾åƒ\n",
    "- guidance_scale (`float`, *optional*, defaults to 7.5):\n",
    "  - è¾ƒé«˜çš„æŒ‡å¯¼æ¯”ä¾‹ä¼šå¯¼è‡´å›¾åƒä¸æç¤ºå¯†åˆ‡ç›¸å…³ï¼Œä½†ä¼šç‰ºç‰²å›¾åƒè´¨é‡ã€‚ å¦‚æœæŒ‡å®šï¼Œå®ƒå¿…é¡»æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°ã€‚ guidance_scale<=1 è¢«å¿½ç•¥ã€‚\n",
    "- negative_prompt (`str` or `List[str]`, *optional*):\n",
    "  - ä¸å¼•å¯¼å›¾åƒç”Ÿæˆçš„æ–‡æœ¬æˆ–æ–‡æœ¬åˆ—è¡¨ã€‚ä¸ä½¿ç”¨æ—¶å¿½ç•¥ï¼Œå¿…é¡»ä¸promptç±»å‹ä¸€è‡´ï¼ˆå¦‚æœ guidance_scale å°äº 1 åˆ™å¿½ç•¥ï¼‰\n",
    "- num_images_per_prompt (`int`, *optional*, defaults to 1):\n",
    "  - æ¯ä¸ªæç¤ºç”Ÿæˆçš„å›¾åƒæ•°é‡\n",
    "  \n",
    "æ›´å¤šå‚æ•°è¯·å‚è€ƒï¼šhttps://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\n",
    "\n",
    "\n",
    "\n",
    "*GPUå†…å­˜ä¸å¤Ÿæ€ä¹ˆåŠï¼Ÿ*\n",
    "- *è¯•ä¸€è¯•åˆ†è¾¨ç‡å°ä¸€ç‚¹çš„å›¾ç‰‡*\n",
    "- *å‡å°‘ç”Ÿæˆå›¾ç‰‡çš„æ•°é‡*\n",
    "- *å‡çº§æœºå‹*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1874593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move Model to the GPU\n",
    "torch.cuda.empty_cache()\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# V1 Max-H:512,Max-W:512\n",
    "# V2 Max-H:768,Max-W:768\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "prompts =[\n",
    "    \"Eiffel tower landing on the Mars\",\n",
    "    \"a photograph of an astronaut riding a horse,van Gogh style\",\n",
    "]\n",
    "generated_images = pipe(\n",
    "    prompt=prompts,\n",
    "    height=512,\n",
    "    width=512,\n",
    "    num_images_per_prompt=1\n",
    ").images  # image here is in [PIL format](https://pillow.readthedocs.io/en/stable/)\n",
    "\n",
    "print(f\"Prompts: {prompts}\\n\")\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "for image in generated_images:\n",
    "    display(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c397444",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.éƒ¨ç½²æ¨¡å‹è‡³Sagemaker Inference Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521b7773",
   "metadata": {},
   "source": [
    "æ„å»ºå’Œè®­ç»ƒæ¨¡å‹åï¼Œæ‚¨å¯ä»¥å°†æ¨¡å‹éƒ¨ç½²è‡³ç»ˆç«¯èŠ‚ç‚¹ï¼Œä»¥ä¸­è·å–é¢„æµ‹æ¨ç†ç»“æœã€‚\n",
    "\n",
    "ä½¿ç”¨ SageMaker æ‰˜ç®¡æœåŠ¡éƒ¨ç½²æ¨¡å‹æœ‰å¤šç§é€‰æ‹©ã€‚ ä½ å¯ä»¥ä½¿ç”¨ AWS å¼€å‘å·¥å…·åŒ…ï¼ˆä¾‹å¦‚ï¼ŒPython å¼€å‘å·¥å…·åŒ… (Boto3)ï¼‰ã€SageMaker Python å¼€å‘å·¥å…·åŒ…ã€AWS CLI ä»¥ç¼–ç¨‹æ–¹å¼éƒ¨ç½²æ¨¡å‹ï¼Œ æˆ–è€…æ‚¨å¯ä»¥ä½¿ç”¨ SageMaker æ§åˆ¶å°ä»¥äº¤äº’æ–¹å¼éƒ¨ç½²æ¨¡å‹ã€‚\n",
    "\n",
    "ä½¿ç”¨ SageMaker æ‰˜ç®¡æœåŠ¡éƒ¨ç½²æ¨¡å‹æ˜¯ä¸€ä¸ªä¸‰æ­¥è¿‡ç¨‹ï¼Œå¦‚æœæ‚¨ä½¿ç”¨ é€‚ç”¨äº Python (Boto3)ã€AWS CLI æˆ– SageMaker æ§åˆ¶å°çš„ AWS å¼€å‘å·¥å…·åŒ…ï¼š\n",
    "    \n",
    "    1.åœ¨ SageMaker ä¸­åˆ›å»º SageMaker æ¨¡å‹ã€‚\n",
    "    2.ä¸º HTTPS ç«¯ç‚¹åˆ›å»ºç«¯ç‚¹é…ç½®ã€‚\n",
    "    3.åˆ›å»º HTTPS ç«¯ç‚¹ã€‚\n",
    "    \n",
    "ä½¿ç”¨ SageMaker Python å¼€å‘å·¥å…·åŒ…éƒ¨ç½²æ¨¡å‹ä¸éœ€è¦æ‚¨åˆ›å»ºç»ˆç«¯èŠ‚ç‚¹é…ç½®ã€‚ å› æ­¤ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸¤æ­¥è¿‡ç¨‹ï¼š\n",
    "    \n",
    "    1.ä»åˆ›å»ºæ¨¡å‹å¯¹è±¡ Modelå¯ä»¥éƒ¨ç½²åˆ° HTTPS ç«¯ç‚¹çš„ç±»ã€‚\n",
    "    2.ä½¿ç”¨æ¨¡å‹å¯¹è±¡çš„é¢„æ„å»ºåˆ›å»º HTTPS ç«¯ç‚¹ deploy()æ–¹æ³•ã€‚ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6154598f",
   "metadata": {},
   "source": [
    "### ç¼–å†™åˆå§‹åŒ–çš„Sagemakerä»£ç ç”¨äºéƒ¨ç½²æ¨ç†ç»ˆç«¯èŠ‚ç‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab2ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14eeb63",
   "metadata": {},
   "source": [
    "### åˆ›å»ºè‡ªå®šä¹‰æ¨ç† inference.py è„šæœ¬\n",
    "\n",
    "è¦ä½¿ç”¨è‡ªå®šä¹‰æ¨ç†è„šæœ¬ï¼Œæ‚¨éœ€è¦åˆ›å»ºä¸€ä¸ª inference.py è„šæœ¬ã€‚ \n",
    "åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ç¼–å†™ model_fn ä»¥æ­£ç¡®åŠ è½½æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¹¶ç¼–å†™ predict_fn ä»¥å¤„ç†æ•°æ®ã€‚\n",
    "\n",
    "æ›´å¤šæ–¹æ³•ï¼Œè¯·å‚è€ƒéƒ¨ç½²HuggingFaceæ¨¡å‹åˆ°Sagemakerä¸­ï¼šhttps://huggingface.co/docs/sagemaker/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4323cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./$SD_MODEL/code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099831cb",
   "metadata": {},
   "source": [
    "#### ä¸ºæ¨¡å‹åˆ›å»ºæ‰€éœ€ä¾èµ–å£°æ˜çš„æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d35c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%writefile ./$SD_MODEL/code/requirements.txt\n",
    "diffusers==0.16.1\n",
    "transformers==4.29.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e427ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./$SD_MODEL/code/inference.py\n",
    "import base64\n",
    "import torch\n",
    "from io import BytesIO\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    # Load stable diffusion and move it to the GPU\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_dir, torch_dtype=torch.float16)\n",
    "    pipe = pipe.to(\"cuda\")\n",
    "\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def predict_fn(data, pipe):\n",
    "\n",
    "    # get prompt & parameters\n",
    "    prompt = data.pop(\"prompt\", \"\")\n",
    "    # set valid HP for stable diffusion\n",
    "    height = data.pop(\"height\", 512)\n",
    "    width = data.pop(\"width\", 512)\n",
    "    num_inference_steps = data.pop(\"num_inference_steps\", 50)\n",
    "    guidance_scale = data.pop(\"guidance_scale\", 7.5)\n",
    "    num_images_per_prompt = data.pop(\"num_images_per_prompt\", 1)\n",
    "    # run generation with parameters\n",
    "    generated_images = pipe(\n",
    "        prompt=prompt,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale,\n",
    "        num_images_per_prompt=num_images_per_prompt,\n",
    "    )[\"images\"]\n",
    "\n",
    "    # create response\n",
    "    encoded_images = []\n",
    "    for image in generated_images:\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        encoded_images.append(base64.b64encode(buffered.getvalue()).decode())\n",
    "\n",
    "    # create response\n",
    "    return {\"generated_images\": encoded_images}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4846889",
   "metadata": {},
   "source": [
    "#### æ‰“åŒ…æ¨¡å‹å¹¶ä¸Šä¼ è‡³S3æ¡¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4509c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Package model, Estimated time to spend 5min\n",
    "!echo $(date)\n",
    "\n",
    "!tar --exclude .git --use-compress-program=pigz -pcvf ./$SD_MODEL'.tar.gz' -C ./$SD_MODEL/ .\n",
    "\n",
    "!echo $(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e23dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "# upload model.tar.gz to s3, Estimated time to spend 30s(V1), 1min(V2)\n",
    "sd_model_uri=S3Uploader.upload(local_path=f\"{SD_MODEL}.tar.gz\", desired_s3_uri=f\"s3://{sess.default_bucket()}/stable-diffusion\")\n",
    "print(f\"=======S3 File Location========\\nmodel uploaded to:\\n{sd_model_uri}\")\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a7de00",
   "metadata": {},
   "source": [
    "#### ä½¿ç”¨HuggingFaceå°†æ¨¡å‹éƒ¨ç½²è‡³SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init variables\n",
    "huggingface_model = {}\n",
    "predictor = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99931527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model[SD_MODEL] = HuggingFaceModel(\n",
    "    model_data=sd_model_uri, # path to your model and script\n",
    "    role=role, # iam role with permissions to create an Endpoint\n",
    "    transformers_version=\"4.26.0\", # transformers version used\n",
    "    pytorch_version=\"1.13.1\", # pytorch version used\n",
    "    py_version='py39', # python version used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac51a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the endpoint endpoint, Estimated time to spend 5min(V1), 8min(V2)\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "predictor[SD_MODEL] = huggingface_model[SD_MODEL].deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    endpoint_name=f\"{SD_MODEL}-endpoint\"\n",
    ")\n",
    "\n",
    "print(f\"\\n{datetime.datetime.now()}\")\n",
    "print(f\"\\n{SD_MODEL}-endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42f4442",
   "metadata": {},
   "source": [
    "#### åŸºäºæ¨ç†ç»ˆç«¯èŠ‚ç‚¹ç”Ÿæˆè‡ªå®šä¹‰å›¾ç‰‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804494ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "# helper decoder\n",
    "def decode_base64_image(image_string):\n",
    "    base64_image = base64.b64decode(image_string)\n",
    "    buffer = BytesIO(base64_image)\n",
    "    return Image.open(buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run prediction\n",
    "response = predictor[SD_MODEL].predict(data={\n",
    "    \"prompt\": [\n",
    "        \"Eiffel tower landing on the Mars\",\n",
    "#         \"a photograph of an astronaut riding a horse\",\n",
    "    ],\n",
    "    \"height\" : 512,\n",
    "    \"width\" : 512,\n",
    "    \"num_images_per_prompt\":1\n",
    "  }\n",
    ")\n",
    "\n",
    "#decode images\n",
    "decoded_images = [decode_base64_image(image) for image in response[\"generated_images\"]]\n",
    "\n",
    "#visualize generation\n",
    "for image in decoded_images:\n",
    "    display(image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
